\documentclass{beamer}
\beamertemplatenavigationsymbolsempty
\usecolortheme{beaver}
\setbeamertemplate{blocks}[rounded=true, shadow=true]
\setbeamertemplate{footline}[page number]
%
\usepackage[utf8]{inputenc}
\usepackage[english,russian]{babel}
\usepackage{amssymb,amsfonts,amsmath,mathtext}
\usepackage{subfig}
\usepackage[all]{xy} % xy package for diagrams
\usepackage{array}
\usepackage{multicol} % many columns in slide
\usepackage{hyperref} % urls
\usepackage{hhline} %tables
\usepackage{comment} %comments
\usepackage{adjustbox}
\usepackage{multirow}
\usepackage{booktabs}
\newcommand{\blambda}{\boldsymbol{\lambda}}

\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}

% Your figures are here:
\graphicspath{ {../figures/} }

%----------------------------------------------------------------------------------------------------------

\title[\hbox to 56mm{Применение синтетических данных, полученных с помощью генеративной нейросети, для повышения качества моделей детекции}]{Применение синтетических данных, полученных с помощью генеративной нейросети, для повышения качества моделей детекции}
\subtitle{\textcolor{black}{Выпускная квалификационная работа бакалавра}}
\author[И.\,Д.Степанов]{
    Степанов Илья Дмитриевич\\
    Научный руководитель: к.ф.-м.н. А.\,В.~Грабовой\\
    Научный констультант: А.\,В.~Филатов
}
\institute[МФТИ (НИУ)]{
\small{
    Кафедра интеллектуальных систем ФПМИ МФТИ\\
    Специализация: Интеллектуальный анализ данных\\
    Направление: 01.03.02 Прикладная математика и информатика
}}
\date{2025}


%----------------------------------------------------------------------------------------------------------
\begin{document}
%----------------------------------------------------------------------------------------------------------

\begin{frame}

    \thispagestyle{empty}
    \maketitle

\end{frame}

%-----------------------------------------------------------------------------------------------------

 \begin{frame}{Применение синтетических данных для детекции}


{\small
\textbf{Задача}

Создание высококачественных аугментаций с помощью генеративной нейросети для повышения качества моделей детекции.

\vspace{5pt}

\textbf{Проблема}

Существующие методы генеративной аугментации для задачи детекции имеют недостатки: генерация объектов исходного класса; аугментация фона вместо самих объектов; аугментация изображений, адаптированная под конкретную прикладную задачу.

\vspace{5pt}

\textbf{Цель}

Разработать автоматизированный алгоритм, способный генерировать качественные аугментации и нивелировать недостатки существующих подходов. Провести сравнительный анализ влияния аугментаций и исследовать вклад отдельных компонентов метода.
}



\end{frame}
%------------------------------------------------------------------------------------------

\begin{frame}{Модель детекции}
\begin{center}

Рассмотрим модель детекции как отображение:
\[
D_{\omega} : X \to \mathcal{F}(\hat{T}),
\]
\end{center}
где $X$ --- множество изображений, $\hat{T}$ — пространство аннотаций для объектов, предсказанных моделью. $\mathcal{F}(\hat{T})$ — пространство предсказанных аннотаций изображений.

\begin{center}
Пусть $\mathcal{L}(\omega)$ --- функция потерь модели детекции. Решается следующая оптимизационная задача:
\end{center}
\[
\omega^* = \arg\min_{\omega}\;\mathcal{L}(\omega),
\]




\end{frame}

% \begin{frame}{Постановка задачи}
% Рассмотрим произвольную модель детекции как отображение:
% \[
% D: X \to \mathcal{F}(\hat{T}),
% \]

% где $X$ --- множество изображений, $\hat{T}$ — пространство аннотаций для отдельных объектов предсказанных моделью. $\mathcal{F}(\hat{T}) \subseteq 2^{\hat{T}}$ — пространство предсказанных аннотаций изображений множества $X$.
% \end{frame}
% %------------------------------------------------------------------------------------------

% \begin{frame}{Постановка задачи}


% Определим функцию потерь для модели детекции YOLO $f_{\theta}$:
% \begin{align*}
% \mathcal{L}_{YOLO}(\theta) &= \lambda_{\text{coord}} \sum_{i=1}^{S^2} \sum_{j=1}^{K} \textbf{I}_{ij}^{\text{obj}} 
% \left[ (x^{gt}_i - \hat{x}_i)^2 + (y^{gt}_i - \hat{y}_i)^2 \right] \notag \\
% &+ \lambda_{\text{coord}} \sum_{i=1}^{S^2} \sum_{j=1}^{K} \textbf{I}_{ij}^{\text{obj}} 
% \left[ (\sqrt{w^{gt}_i} - \sqrt{\hat{w}_i})^2 + (\sqrt{h^{gt}_i} - \sqrt{\hat{h}_i})^2 \right] \notag \\
% &+ \sum_{i=1}^{S^2} \sum_{j=1}^{K} \textbf{I}_{ij}^{\text{obj}} (\hat{C}_i - C_i)^2 
% + \lambda_{\text{noobj}} \sum_{i=1}^{S^2} \sum_{j=1}^{K} \textbf{I}_{ij}^{\text{noobj}} (\hat{C}_i - C_i)^2 \notag \\
% &+ \sum_{i=1}^{S^2} \textbf{I}_{i}^{\text{obj}} \sum_{c \in \mathcal{C}} (\hat{p}_i(c) - p_i(c))^2,
% \end{align*}

% \end{frame}

% \begin{frame}{Постановка задачи}
% \small{
% где 
% $S \times S$ — размер сетки, на которую разбивается изображение,
% $K$ — количество предсказанных ограничивающих прямоугольников в каждой ячейке сетки,  
% $\lambda_{\text{coord}}, \lambda_{\text{noobj}}$ — коэффициенты, регулирующие вклад  в функцию потерь,
% $\textbf{I}_{ij}^{\text{obj}}$ — индикатор наличия объекта в $j$-ом прямоугольнике $i$-й ячейки,  
% $\textbf{I}_{ij}^{\text{noobj}}$ — индикатор отсутствия объекта в $j$-ом прямоугольнике $i$-й ячейки,  
% $(x^{gt}_i, y^{gt}_i, w^{gt}_i, h^{gt}_i)$ — координаты центра, ширина и высота истинного ограничивающего прямоугольника для $i$-й ячейки,  
% $(\hat{x}_i, \hat{y}_i, \hat{w}_i, \hat{h}_i)$ — предсказанные координаты ограничивающего прямоугольника для $i$-й ячейки,  
% $C_i$ и $\hat{C}_i$ — истинная и предсказанная вероятность наличия объекта в $i$-й ячейке,  \(\mathcal{C}\) — множество классов объектов,
% $p_i(c)$ и $\hat{p}_i(c)$ — истинная и предсказанная вероятность принадлежности объекта классу $c$ для $i$-й ячейки.}

% \begin{center}
% Решается следующая оптимизационная задача:
% \end{center}
% \[
% \theta^* = \arg\min_{\theta}\;\mathcal{L}_{YOLO}(\theta),
% \]

% \end{frame}
% \begin{frame}{Постановка задачи}

% Для вычисления следующей функции потерь необходимо определить оптимальное соответствие с помощью Венгерского алгоритма о назначениях.
% \begin{align*}
% \hat\sigma 
% &= \arg\min_{\sigma\in S_N} \sum_{i=1}^N \Bigl[
% -\,\mathbf{I}_{\{c_i\neq\varnothing\}}\;\hat p_{\sigma(i)}(c_i)
% +\;\mathbf{I}_{\{c_i\neq\varnothing\}}\;\Bigl(\lambda_{L1}\,\bigl\lVert b_i - \hat b_{\sigma(i)}\bigr\rVert_{1}
% \;
% \\
% &\quad
% +
% \;\lambda_{\mathrm{giou}}\;(1 - \mathrm{GIoU}\bigl(a_i,\;\hat a_{\sigma(i)})\bigr)\Bigr)
% \Bigr],
% \end{align*}

% Определим функцию потерь для модели детекции DETR $g_{\phi}$:

% \begin{align*}
% \mathcal{L}_{DETR}(\phi)
% &= \sum_{i=1}^N \Bigl[
% -\,\log \hat p_{\hat\sigma_{\phi}(i)}\bigl(c_i\bigr)
% \;+\;
% \mathbf{I}_{\{\,c_i \neq \varnothing\,\}}\Bigl(
% \lambda_{L1}\,\bigl\lVert b_i - \hat b_{\hat\sigma_{\phi}(i)}\bigr\rVert_{1}
% \\
% &\quad
% +
% \lambda_{\mathrm{giou}}\;{(1 - \mathrm{GIoU}}\bigl(a_i,\;\hat a_{\hat\sigma_{\phi}(i)})\bigr)
% \Bigr)
% \Bigr],
% \end{align*}

% \end{frame}

% \begin{frame}{Постановка задачи}
% \small{
% где $\hat\sigma$ — оптимальное соответствие между истинными аннотациями и предсказанными,
% $S_N$ — множество инъективных отображений из ${\{1,\dots,\ M\}}$ в ${\{1,\dots, \ N\}}$,
% $M$ — число истинных аннотаций объектов на изображении,
% $N > M$ — число предсказаных аннотаций объектов на изображении,
% $\mathbf{I}_{\{c_i\neq\varnothing\}}$ — индикатор наличия объекта в истинном наборе,
% $c_i$ — истинная метка класса объекта $i$,
% $\hat p_j(c)$ — предсказанная моделью вероятность класса $c$ для аннотации $j$,
% $a_i$ — истинная аннотация объекта $i$, $b_i$ — истинный ограничивающий прямоугольник объекта $i$, 
% $\hat a_j$ — предсказанная аннотация объекта $j$, $\hat b_j$ — предсказанный ограничивающий прямоугольник объекта $j$, $\lambda_{L_1}$ и $\lambda_{\text{giou}}$ — регуляризационные коэффициенты для задачи поиска оптимального соответствия, GIoU — функция качества, оценивающая совпадение предсказанной и истинной аннотации.}

% \begin{center}
% Решается следующая оптимизационная задача:
% \end{center}
% \[
% \phi^* = \arg\min_{\phi}\;\mathcal{L}_{DETR}(\phi).
% \]

% % Пусть $ P_{\text{data}}(x) $ — распределение входных изображений, а $ P_{\text{aug}}(y) $ — распределение аугментированных изображений

% % Задача заключается в минимизации дивергенции Кульбака-Лейблера между этими распределениями:

% % \begin{center}
% %     $D_{\text{KL}}(P_{\text{aug}}(y) \parallel P_{\text{data}}(x)) \to 0.$
% % \end{center}
% \end{frame}


\begin{frame}{Функция качества $\text{mAP}$}
Рассмотрим функцию $\text{mAP}$ (mean Average Precision):
\begin{center}
   $\text{mAP}: \{ \hat{T} \}  \times \{ T \} \times [0,1] \to [0,1]$,
\end{center}



Для каждого класса \(c \in \mathcal{C}\) вычисляется функция \text{AP} (Average Precision):
\[
\text{AP}(c, \tau, t, \hat{t}) = \int_{0}^{1} P_c(r, \tau, t, \hat{t}) \, dr,
\]
где \(P_c(r, \tau, t, \hat{t})\) --- функция, задающая кривую Precision–Recall для класса \(c\) при пороге $\tau$, $t \subseteq T$ — множество истинных аннотаций для класса \(c\), $\hat{t} \subseteq \hat{T}$ — множество предсказанных аннотаций для класса \(c\).
\[
\text{mAP} = \frac{1}{|\mathcal{C}|} \sum_{c \in \mathcal{C}} \text{AP}(c, \tau, t, \hat{t}).
\]

\end{frame}


\begin{frame}{Функция качества $\text{mAP}_{50:95}$}

Рассмотрим функцию $\text{mAP}_{50:95}$:
\begin{center}
   $\text{mAP}_{50:95}:  \{ \hat{T} \}  \times \{ T \} \to [0,1]$,
\end{center}

Определим промежуточную функцию $\text{AP}_{50:95}$ для каждого класса $c$:
\[
\text{AP}_{50:95}(c,\,t,\,\hat{t})
\;=\;
\frac{1}{10} 
\sum_{\tau \in \{0.50,\,0.55,\,\dots,\,0.95\}}
\text{AP}(c,\,\tau,\,t,\,\hat{t}).
\]

\[
\text{mAP}_{50:95}
\;=\;
\frac{1}{|\mathcal{C}|}
\sum_{c \in \mathcal{C}}
\text{AP}_{50:95}(c,\,t,\,\hat{t}).
\]

\end{frame}
\begin{frame}{Генеративная аугментация}
Рассмотрим модель генеративной аугментации как отображение:

\begin{center}

$
F_{\psi,\alpha,\beta,\gamma} : X \times [0,1] \;\longrightarrow\; (X_{\text{aug}} \times T_{\text{aug}}) \;\cup\; \{\varnothing\}, 
$

\end{center}
\begin{center}
$ f_{\psi}: X \to M \times L \times T_{\text{aug}}$
\end{center}
\begin{center}
$ g_{\alpha}: X \times L \to P$
\end{center}
\begin{center}
$ h_{\beta}: X \times M \times P \to X_{\text{aug}}$

\end{center}
\begin{center}
$ r_{\gamma}: Y \times M \times L \times [0,1] \to \{0,1\}$

\end{center}

% Тут у меня T_{\text{aug}} это пространство аннотаций для отдельных объектов, т е я по сути беру изображение генерю агументацию и выдаю аннотацию ТОЛЬКО для аугментации

где $X$ — пространство изображений,  
$X_{\text{aug}}$ — пространство аугментированных изображений, $T_{\text{aug}}$ — пространство аннотаций аугментированных объектов, $f_{\psi}$ — модель детекции объекта, $g_{\alpha}$ — модель генерации текстового запроса, $h_{\beta}$ — модель генерации нового объекта, $r_{\gamma}$ — модель фильтрации генераций,
$M$ — пространство масок объектов,  $P$ — пространство текстовых запросов, 
$L \subset P$ — пространство классов объектов.
\end{frame}
\begin{frame}{Генеративная аугментация}
\[
F_{\psi,\alpha,\beta,\gamma}(x, \tau)
=
\begin{cases}
(x_\mathrm{aug},\,a_\mathrm{aug}), 
& \text{если } r_{\gamma}\bigl(x_\mathrm{aug},\,m,\,\ell,\,\tau\bigr)=1,\\[1em]
\varnothing, 
& \text{если } r_{\gamma}\bigl(x_\mathrm{aug},\,m,\,\ell,\,\tau\bigr)=0,
\end{cases}
\]
\[
\text{где }
(m,\,\ell,\,a_\mathrm{aug}) = f_{\psi}(x),
\quad
x_\mathrm{aug} = h_{\beta}\bigl(x,\,m,\,g_{\alpha}(x,\ell)\bigr).
\]

\vspace{0.5em}
\begin{enumerate}
  \item \(f_{\psi}\) извлекает маску и аннотацию объекта.
  \item \(g_{\alpha}\)  формирует текстовый запрос для нового объекта на основе изначального класса и исходного изображения.
  \item \(h_{\beta}\) генерирует аугментацию с помощью маски, текстового запроса и исходного изображения.
  \item \(r_{\gamma}\) фильтрует некачественные аугментации с заданным порогом \(\tau\in[0,1]\).
\end{enumerate}
\end{frame}


\begin{frame}{Генеративная аугментация}

Пусть $\mathcal{D} = \mathcal{D}_{\text{val}} \ \sqcup \ \mathcal{D}_{\text{train}}$. Рассмотрим аугментированный датасет для задачи детекции:
\[
\mathcal{D}_{\text{aug}}(\tau) =
\left\{
  (x_i^{\text{aug}},\,t_i^{\text{aug}}), \
  i = 1,\dots,m
\right\},
\]

где $(x_i, t_i) \in \mathcal{D}_{\mathrm{train}}$,
$(x_i^{\mathrm{aug}}, a_i^{\mathrm{aug}}) = F_{\psi,\alpha,\beta,\gamma}(x_i, \tau)$,
$a_i^* \in t_i$ — аннотация объекта с наибольшей площадью ограничивающего прямоугольника,
$t_i^{\mathrm{aug}} = \bigl(t_i \setminus \{\,a_i^*\,\}\bigr) \cup \{\,a_i^{\mathrm{aug}}\,\}$ — аннотация аугментированного изображения,
$\tau \in [0,1]$ — пороговое значение для модели фильтрации.

\end{frame}




\begin{frame}{Генеративная аугментация}

\textbf{Утверждение 1:}\par
\small{
Пусть $\mathcal{D}_{\text{val}} =
\left\{
  (x_i,\,t_i), \
  i = 1,\dots,k
\right\}$. Существует такое значение $\tau^*\in[0,1]$, что модели детекции $f_{\theta_1}$ и $g_{\phi_1}$, обученные на объединённом датасете $\mathcal{D}_{\mathrm{aug}}(\tau^*)\sqcup\mathcal{D}_{\mathrm{train}}$, достигают не меньшего значения по функциям $\mathrm{mAP}_{50}$ и $\mathrm{mAP}_{50:95}$ на $\mathcal{D}_{\text{val}}$, чем модели $f_{\theta_2}$ и $g_{\phi_2}$, обученные на $\mathcal{D}_{\text{train}}$. То есть:

\begin{center}
$\mathrm{mAP}_{50}\bigl(\{f_{\theta_1}(x_i)\}_{i=1}^k,\{t_i\}_{i=1}^k\bigr)\ge\mathrm{mAP}_{50}\bigl(\{f_{\theta_2}(x_i)\}_{i=1}^k,\{t_i\}_{i=1}^k\bigr)$,  
$\mathrm{mAP}_{50:95}\bigl(\{f_{\theta_1}(x_i)\}_{i=1}^k,\{t_i\}_{i=1}^k\bigr)\ge\mathrm{mAP}_{50:95}\bigl(\{f_{\theta_2}(x_i)\}_{i=1}^k,\{t_i\}_{i=1}^k\bigr)$,  
$\mathrm{mAP}_{50}\bigl(\{g_{\phi_1}(x_i)\}_{i=1}^k,\{t_i\}_{i=1}^k\bigr)\ge\mathrm{mAP}_{50}\bigl(\{g_{\phi_2}(x_i)\}_{i=1}^k,\{t_i\}_{i=1}^k\bigr)$,  
$\mathrm{mAP}_{50:95}\bigl(\{g_{\phi_1}(x_i)\}_{i=1}^k,\{t_i\}_{i=1}^k\bigr)\ge\mathrm{mAP}_{50:95}\bigl(\{g_{\phi_2}(x_i)\}_{i=1}^k,\{t_i\}_{i=1}^k\bigr)$.
\end{center}}

\end{frame}

%------------------------------------------------------------------------------------------

%------------------------------------------------------------------------------------------

%------------------------------------------------------------------------------------------

\begin{frame}{Исследование влияния компонент: текстовый запрос}

\begin{center}
Рассмотрим модель аугментации следующего вида:
\end{center}
\begin{center}
$F'_{\psi,\beta,\gamma}(x, \tau) \;=\;
\begin{cases}
\bigl(x_{\text{aug}}, a_{\text{aug}}), 
& \text{если } r_{\gamma}\bigl(x_{\text{aug}},\,m,\,\ell,\,\tau\bigr) = 1,\\[1em]
\varnothing, 
& \text{если } r_{\gamma}\bigl(x_{\text{aug}},\,m,\,\ell,\,\tau\bigr) = 0.
\end{cases}
$
\end{center}
где 
$ 
(m,\,\ell,\, a_{\text{aug}}) = f_{\psi}(x),  \ x_{\text{aug}} = h_{\beta}\bigl(x,\,m,\, \ell \bigr)$.
\begin{center}
Рассмотрим аугментированный датасет для задачи детекции:
\end{center}
\[
\mathcal{D}^{'}_{\text{aug}}(\tau) =
\left\{
  (x_i^{\text{aug}},\,t_i^{\text{aug}}), \
  i = 1,\dots,n
\right\},
\]

где $(x_i, t_i) \in \mathcal{D}_{\mathrm{train}}$,
$(x_i^{\mathrm{aug}}, a_i^{\mathrm{aug}}) = F^{'}_{\psi,\beta,\gamma}(x_i, \tau)$,
$a_i^* \in t_i$ — аннотация объекта с наибольшей площадью ограничивающего прямоугольника,
$t_i^{\mathrm{aug}} = \bigl(t_i \setminus \{\,a_i^*\,\}\bigr) \cup \{\,a_i^{\mathrm{aug}}\,\}$ — аннотация аугментированного изображения,
$\tau \in [0,1]$ — пороговое значение для модели фильтрации.


\end{frame}

\begin{frame}{Исследование влияния компонент: текстовый запрос}

\textbf{Утверждение 2:}\par

\small{
Пусть $\mathcal{D}_{\text{val}} =
\left\{
  (x_i,\,t_i), \
  i = 1,\dots,k
\right\}$. Существует такое значение $\tau^*\in[0,1]$, что модели детекции $f_{\theta_1}$ и $g_{\phi_1}$, обученные на объединённом датасете $\mathcal{D}_{\mathrm{aug}}(\tau^*)\sqcup\mathcal{D}_{\mathrm{train}}$, достигают не меньшего значения по функциям $\mathrm{mAP}_{50}$ и $\mathrm{mAP}_{50:95}$ на $\mathcal{D}_{\text{val}}$, чем модели $f_{\theta_2}$ и $g_{\phi_2}$, обученные на $\mathcal{D}^{'}_{\text{aug}}(\tau^{*}) \sqcup \mathcal{D}_{\text{train}}$. То есть:

\begin{center}
$\mathrm{mAP}_{50}\bigl(\{f_{\theta_1}(x_i)\}_{i=1}^k,\{t_i\}_{i=1}^k\bigr)\ge\mathrm{mAP}_{50}\bigl(\{f_{\theta_2}(x_i)\}_{i=1}^k,\{t_i\}_{i=1}^k\bigr)$,  
$\mathrm{mAP}_{50:95}\bigl(\{f_{\theta_1}(x_i)\}_{i=1}^k,\{t_i\}_{i=1}^k\bigr)\ge\mathrm{mAP}_{50:95}\bigl(\{f_{\theta_2}(x_i)\}_{i=1}^k,\{t_i\}_{i=1}^k\bigr)$,  
$\mathrm{mAP}_{50}\bigl(\{g_{\phi_1}(x_i)\}_{i=1}^k,\{t_i\}_{i=1}^k\bigr)\ge\mathrm{mAP}_{50}\bigl(\{g_{\phi_2}(x_i)\}_{i=1}^k,\{t_i\}_{i=1}^k\bigr)$,  
$\mathrm{mAP}_{50:95}\bigl(\{g_{\phi_1}(x_i)\}_{i=1}^k,\{t_i\}_{i=1}^k\bigr)\ge\mathrm{mAP}_{50:95}\bigl(\{g_{\phi_2}(x_i)\}_{i=1}^k,\{t_i\}_{i=1}^k\bigr)$.
\end{center}}

\end{frame}

\begin{frame}{Исследование влияния компонент: фильтрация}

Аналогично рассмотрим модель аугментации следующего вида:
\begin{center}
$F^{''}_{\psi,\alpha,\beta}(x, \tau) \ = \ (x_{\text{aug}}, a_{\text{aug}})$
\end{center}
где 
$ 
(m,\,\ell,\, a_{\text{aug}}) = f_{\psi}(x),  \ x_{\text{aug}} = h_{\beta}\bigl(x,\,m,\,g_{\alpha}(x, \ell)\bigr)$.

\begin{center}
Рассмотрим аугментированный датасет для задачи детекции:
\end{center}
\[
\mathcal{D}^{''}_{\text{aug}}(\tau) =
\left\{
  (x_i^{\text{aug}},\,t_i^{\text{aug}}), \
  i = 1,\dots,n
\right\},
\]
% \;\middle|\;
%   (x_i^{\text{aug}},\,t_i^{\text{aug}}) \in F_{\psi,\alpha,\beta,\gamma}(x_i, \tau),\;
%   x_i \in \pi_1(\mathcal{D}_{\text{train}}),\;

где $(x_i, t_i) \in \mathcal{D}_{\mathrm{train}}$,
$(x_i^{\mathrm{aug}}, a_i^{\mathrm{aug}}) = F^{''}_{\psi,\alpha,\beta}(x_i, \tau)$,
$a_i^* \in t_i$ — аннотация объекта с наибольшей площадью ограничивающего прямоугольника,
$t_i^{\mathrm{aug}} = \bigl(t_i \setminus \{\,a_i^*\,\}\bigr) \cup \{\,a_i^{\mathrm{aug}}\,\}$ — аннотация аугментированного изображения,
$\tau \in [0,1]$ — пороговое значение для модели фильтрации.


\end{frame}

\begin{frame}{Исследование влияния компонент: фильтрация}

\textbf{Утверждение 3:}\par
\small{
Пусть $\mathcal{D}_{\text{val}} =
\left\{
  (x_i,\,t_i), \
  i = 1,\dots,k
\right\}$. Существует такое значение $\tau^*\in[0,1]$, что модели детекции $f_{\theta_1}$ и $g_{\phi_1}$, обученные на объединённом датасете $\mathcal{D}_{\mathrm{aug}}(\tau^*)\sqcup\mathcal{D}_{\mathrm{train}}$, достигают не меньшего значения по функциям $\mathrm{mAP}_{50}$ и $\mathrm{mAP}_{50:95}$ на $\mathcal{D}_{\text{val}}$, чем модели $f_{\theta_2}$ и $g_{\phi_2}$, обученные на $\mathcal{D}^{''}_{\text{aug}}(\tau^{*}) \sqcup \mathcal{D}_{\text{train}}$. То есть:


\begin{center}
$\mathrm{mAP}_{50}\bigl(\{f_{\theta_1}(x_i)\}_{i=1}^k,\{t_i\}_{i=1}^k\bigr)\ge\mathrm{mAP}_{50}\bigl(\{f_{\theta_2}(x_i)\}_{i=1}^k,\{t_i\}_{i=1}^k\bigr)$,  
$\mathrm{mAP}_{50:95}\bigl(\{f_{\theta_1}(x_i)\}_{i=1}^k,\{t_i\}_{i=1}^k\bigr)\ge\mathrm{mAP}_{50:95}\bigl(\{f_{\theta_2}(x_i)\}_{i=1}^k,\{t_i\}_{i=1}^k\bigr)$,  
$\mathrm{mAP}_{50}\bigl(\{g_{\phi_1}(x_i)\}_{i=1}^k,\{t_i\}_{i=1}^k\bigr)\ge\mathrm{mAP}_{50}\bigl(\{g_{\phi_2}(x_i)\}_{i=1}^k,\{t_i\}_{i=1}^k\bigr)$,  
$\mathrm{mAP}_{50:95}\bigl(\{g_{\phi_1}(x_i)\}_{i=1}^k,\{t_i\}_{i=1}^k\bigr)\ge\mathrm{mAP}_{50:95}\bigl(\{g_{\phi_2}(x_i)\}_{i=1}^k,\{t_i\}_{i=1}^k\bigr)$.
\end{center}}

\end{frame}

\begin{frame}{Влияние аугментаций}

\begin{table}[p]
\centering
\scriptsize % Еще меньший шрифт
\setlength{\tabcolsep}{2pt} % Минимальные пробелы
\renewcommand{\arraystretch}{0.9} % Уменьшение вертикальных промежутков
\begin{tabular}{cccc|cc}
\toprule
\textbf{Dataset} & \textbf{Model} & \textbf{Setting} & \textbf{Size} & \textbf{$\text{mAP}_{\textbf{50}}$} & \textbf{$\text{mAP}_{\textbf{50:95}}$} \\
\midrule
\multirow{8}{*}{Pascal VOC} 
    & \multirow{4}{*}{DETR}
        & original                     & 4000  & 57.2 & 41.2 \\
        &                              & w/o expanded prompt          & 4000 + 4000  & 55.4 & 38.7 \\
        &                              & w/o filter model             & 4000 + 4000  & 57.4 & 40.9 \\
        &                              & ours                          & 4000 + 4000  & \textbf{58.2} & \textbf{41.4} \\
    \cline{2-6}
    & \multirow{4}{*}{YOLO}
        & original                     & 4000  & 59.6 & 41.5 \\
        &                              & w/o expanded prompt          & 4000 + 4000  & 59.4 & 41.2 \\
        &                              & w/o filter model             & 4000 + 4000  & 61.4 & \textbf{43.2} \\
        &                              & ours                          & 4000 + 4000  & \textbf{61.5} & \textbf{43.2} \\
\midrule
\multirow{8}{*}{COCO} 
    & \multirow{4}{*}{DETR}
        & original                     & 5000 & 26.6 & 17.6 \\
        &                              & w/o expanded prompt          & 5000 + 5000 & 27.5 & \textbf{17.8} \\
        &                              & w/o filter model             & 5000 + 5000 & 26 & 16.5 \\
        &                              & ours                          & 5000 + 5000 & \textbf{27.8} & \textbf{17.8} \\
    \cline{2-6}
    & \multirow{4}{*}{YOLO}
        & original                     & 5000 & 26.7 & 17.4 \\
        &                              & w/o expanded prompt          & 5000 + 5000 & 27.5 & 17.9 \\
        &                              & w/o filter model             & 5000 + 5000 & 27.7 & 17.9 \\
        &                              & ours                          & 5000 + 5000 & \textbf{28.2} & \textbf{18.3} \\
\bottomrule
\end{tabular}
% \caption{Проведение сравнительного анализа значений функций качества $\mathrm{mAP}_{50}$ и $\mathrm{mAP}_{50:95}$ моделей DETR и YOLO, обученных на датасетах Pascal VOC и COCO с применением аугментаций и без них, а также анализ влияния отдельных компонентов.}
% \label{tab:augmented-metrics}
\end{table}
\small{
Проведение сравнительного анализа значений функций качества $\mathrm{mAP}_{50}$ и $\mathrm{mAP}_{50:95}$ моделей DETR и YOLO, обученных на датасетах Pascal VOC и COCO с применением аугментаций и без них, а также анализ влияния отдельных компонентов.
}


\end{frame}
\begin{frame}{Выносится на защиту}

{\begin{enumerate}
\Large
    \item Предложен автоматизированный подход к созданию аугментированных изображений.
    \item Проведены эксперименты, демонстрирующие влияние аугментаций на качество работы модели детекции.
    \item Проведён анализ влияния отдельных компонентов метода на итоговое значение функций качества.
\end{enumerate}}


\end{frame}
%----------------------------------------------------------------------------------------------------------
\end{document}
